{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "454f8bb0-4201-4a3a-b1bb-dcc90b00ec5f",
   "metadata": {},
   "source": [
    "# Diagnostics\n",
    "\n",
    "Some commands to see what's going on in the cluster\n",
    "\n",
    "## Links\n",
    "\n",
    "* [https://kubernetes.io/docs/concepts/architecture/](https://kubernetes.io/docs/concepts/architecture/)\n",
    "* [https://kubernetes.io/docs/tasks/debug/debug-cluster/](https://kubernetes.io/docs/tasks/debug/debug-cluster/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "98355322-d941-46d0-8b65-1d4f4c4ce283",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "all:\n",
      "  hosts:\n",
      "    node1:\n",
      "      ansible_host: xxx.xxx.118.255\n",
      "      ip: xxx.xxx.118.255\n",
      "      access_ip: xxx.xxx.118.255\n",
      "    node2:\n",
      "      ansible_host: xxx.xxx.118.104\n",
      "      ip: xxx.xxx.118.104\n",
      "      access_ip: xxx.xxx.118.104\n",
      "    node3:\n",
      "      ansible_host: xxx.xxx.175.63\n",
      "      ip: xxx.xxx.175.63\n",
      "      access_ip: xxx.xxx.175.63\n",
      "  children:\n",
      "    kube_control_plane:\n",
      "      hosts:\n",
      "        node1:\n",
      "    kube_node:\n",
      "      hosts:\n",
      "        node2:\n",
      "        node3:\n",
      "    etcd:\n",
      "      hosts:\n",
      "        node1:\n",
      "    k8s_cluster:\n",
      "      children:\n",
      "        kube_control_plane:\n",
      "        kube_node:\n",
      "    calico_rr:\n",
      "      hosts: {}\n"
     ]
    }
   ],
   "source": [
    "# Print the hosts.yml used for this cluser:\n",
    "! cat ../mycluster/hosts.yml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0d1f78b9-ff2c-42c8-a979-363daa1f020f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[0;32mKubernetes control plane\u001B[0m is running at \u001B[0;33mhttps://xxx.xxx.118.255:6443\u001B[0m\n",
      "\n",
      "To further debug and diagnose cluster problems, use 'kubectl cluster-info dump'.\n"
     ]
    }
   ],
   "source": [
    "! kubectl cluster-info"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "608b5c96-0ce7-4d66-bcbf-a0a88af53f01",
   "metadata": {},
   "source": [
    "**Warning** The output of `kubectl cluster-info dump` is huge. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5b4cc7cf-a1c7-4578-9c8a-6fa16171ca8a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NAMESPACE            NAME                                           READY   STATUS    RESTARTS   AGE\n",
      "kube-system          pod/calico-kube-controllers-6dd874f784-x2bbk   1/1     Running   0          16m\n",
      "kube-system          pod/calico-node-gl8k2                          1/1     Running   0          16m\n",
      "kube-system          pod/calico-node-spg5v                          1/1     Running   0          16m\n",
      "kube-system          pod/calico-node-t5nsj                          1/1     Running   0          16m\n",
      "kube-system          pod/coredns-76b4fb4578-jhsz6                   1/1     Running   0          15m\n",
      "kube-system          pod/coredns-76b4fb4578-rk7zt                   1/1     Running   0          15m\n",
      "kube-system          pod/dns-autoscaler-7979fb6659-h96tg            1/1     Running   0          15m\n",
      "kube-system          pod/kube-apiserver-node1                       1/1     Running   1          18m\n",
      "kube-system          pod/kube-controller-manager-node1              1/1     Running   1          18m\n",
      "kube-system          pod/kube-proxy-5q4lc                           1/1     Running   0          16m\n",
      "kube-system          pod/kube-proxy-d5xd4                           1/1     Running   0          16m\n",
      "kube-system          pod/kube-proxy-n6b5d                           1/1     Running   0          16m\n",
      "kube-system          pod/kube-scheduler-node1                       1/1     Running   1          18m\n",
      "kube-system          pod/metrics-server-5c8c77d7b8-stkx7            1/1     Running   0          14m\n",
      "kube-system          pod/nginx-proxy-node2                          1/1     Running   0          17m\n",
      "kube-system          pod/nginx-proxy-node3                          1/1     Running   0          17m\n",
      "kube-system          pod/nodelocaldns-bph5j                         1/1     Running   0          15m\n",
      "kube-system          pod/nodelocaldns-g9pjp                         1/1     Running   0          15m\n",
      "kube-system          pod/nodelocaldns-r9trt                         1/1     Running   0          15m\n",
      "local-path-storage   pod/local-path-provisioner-6957789775-hxkbg    1/1     Running   0          15m\n",
      "\n",
      "NAMESPACE     NAME                     TYPE        CLUSTER-IP     EXTERNAL-IP   PORT(S)                  AGE\n",
      "default       service/kubernetes       ClusterIP   10.233.0.1     <none>        443/TCP                  18m\n",
      "kube-system   service/coredns          ClusterIP   10.233.0.3     <none>        53/UDP,53/TCP,9153/TCP   15m\n",
      "kube-system   service/metrics-server   ClusterIP   10.233.15.65   <none>        443/TCP                  14m\n",
      "\n",
      "NAMESPACE     NAME                          DESIRED   CURRENT   READY   UP-TO-DATE   AVAILABLE   NODE SELECTOR            AGE\n",
      "kube-system   daemonset.apps/calico-node    3         3         3       3            3           kubernetes.io/os=linux   16m\n",
      "kube-system   daemonset.apps/kube-proxy     3         3         3       3            3           kubernetes.io/os=linux   18m\n",
      "kube-system   daemonset.apps/nodelocaldns   3         3         3       3            3           kubernetes.io/os=linux   15m\n",
      "\n",
      "NAMESPACE            NAME                                      READY   UP-TO-DATE   AVAILABLE   AGE\n",
      "kube-system          deployment.apps/calico-kube-controllers   1/1     1            1           16m\n",
      "kube-system          deployment.apps/coredns                   2/2     2            2           15m\n",
      "kube-system          deployment.apps/dns-autoscaler            1/1     1            1           15m\n",
      "kube-system          deployment.apps/metrics-server            1/1     1            1           14m\n",
      "local-path-storage   deployment.apps/local-path-provisioner    1/1     1            1           15m\n",
      "\n",
      "NAMESPACE            NAME                                                 DESIRED   CURRENT   READY   AGE\n",
      "kube-system          replicaset.apps/calico-kube-controllers-6dd874f784   1         1         1       16m\n",
      "kube-system          replicaset.apps/coredns-76b4fb4578                   2         2         2       15m\n",
      "kube-system          replicaset.apps/dns-autoscaler-7979fb6659            1         1         1       15m\n",
      "kube-system          replicaset.apps/metrics-server-5c8c77d7b8            1         1         1       14m\n",
      "local-path-storage   replicaset.apps/local-path-provisioner-6957789775    1         1         1       15m\n"
     ]
    }
   ],
   "source": [
    "! kubectl get all --all-namespaces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a7ff6cdb-fa71-411f-80a5-a79f4468703e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NAME    STATUS   ROLES                  AGE   VERSION\n",
      "node1   Ready    control-plane,master   18m   v1.23.7\n",
      "node2   Ready    <none>                 17m   v1.23.7\n",
      "node3   Ready    <none>                 17m   v1.23.7\n"
     ]
    }
   ],
   "source": [
    "! kubectl get nodes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15888db9-3971-4632-a1bc-a0c3a109e7c7",
   "metadata": {},
   "source": [
    "**Overview of node status** (https://kubernetes.io/docs/concepts/architecture/nodes/#node-status)[https://kubernetes.io/docs/concepts/architecture/nodes/#node-status}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bf3d8765-7c18-454f-b1f6-2fe242802ce3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name:               node2\n",
      "Roles:              <none>\n",
      "Labels:             beta.kubernetes.io/arch=amd64\n",
      "                    beta.kubernetes.io/os=linux\n",
      "                    kubernetes.io/arch=amd64\n",
      "                    kubernetes.io/hostname=node2\n",
      "                    kubernetes.io/os=linux\n",
      "Annotations:        kubeadm.alpha.kubernetes.io/cri-socket: /var/run/containerd/containerd.sock\n",
      "                    node.alpha.kubernetes.io/ttl: 0\n",
      "                    projectcalico.org/IPv4Address: xxx.xxx.118.104/32\n",
      "                    projectcalico.org/IPv4VXLANTunnelAddr: 10.233.96.0\n",
      "                    volumes.kubernetes.io/controller-managed-attach-detach: true\n",
      "CreationTimestamp:  Tue, 21 Jun 2022 08:11:47 +0000\n",
      "Taints:             <none>\n",
      "Unschedulable:      false\n",
      "Lease:\n",
      "  HolderIdentity:  node2\n",
      "  AcquireTime:     <unset>\n",
      "  RenewTime:       Tue, 21 Jun 2022 08:28:49 +0000\n",
      "Conditions:\n",
      "  Type                 Status  LastHeartbeatTime                 LastTransitionTime                Reason                       Message\n",
      "  ----                 ------  -----------------                 ------------------                ------                       -------\n",
      "  NetworkUnavailable   False   Tue, 21 Jun 2022 08:12:30 +0000   Tue, 21 Jun 2022 08:12:30 +0000   CalicoIsUp                   Calico is running on this node\n",
      "  MemoryPressure       False   Tue, 21 Jun 2022 08:28:49 +0000   Tue, 21 Jun 2022 08:11:47 +0000   KubeletHasSufficientMemory   kubelet has sufficient memory available\n",
      "  DiskPressure         False   Tue, 21 Jun 2022 08:28:49 +0000   Tue, 21 Jun 2022 08:11:47 +0000   KubeletHasNoDiskPressure     kubelet has no disk pressure\n",
      "  PIDPressure          False   Tue, 21 Jun 2022 08:28:49 +0000   Tue, 21 Jun 2022 08:11:47 +0000   KubeletHasSufficientPID      kubelet has sufficient PID available\n",
      "  Ready                True    Tue, 21 Jun 2022 08:28:49 +0000   Tue, 21 Jun 2022 08:12:50 +0000   KubeletReady                 kubelet is posting ready status. AppArmor enabled\n",
      "Addresses:\n",
      "  InternalIP:  xxx.xxx.118.104\n",
      "  Hostname:    node2\n",
      "Capacity:\n",
      "  cpu:                2\n",
      "  ephemeral-storage:  39062284Ki\n",
      "  hugepages-1Gi:      0\n",
      "  hugepages-2Mi:      0\n",
      "  memory:             3927728Ki\n",
      "  pods:               110\n",
      "Allocatable:\n",
      "  cpu:                1900m\n",
      "  ephemeral-storage:  35999800875\n",
      "  hugepages-1Gi:      0\n",
      "  hugepages-2Mi:      0\n",
      "  memory:             3563184Ki\n",
      "  pods:               110\n",
      "System Info:\n",
      "  Machine ID:                 51a9dfcfd4e04f7dae5081b71617bd6f\n",
      "  System UUID:                51a9dfcf-d4e0-4f7d-ae50-81b71617bd6f\n",
      "  Boot ID:                    3d52300a-2d7d-4213-adbd-e003c5a1b266\n",
      "  Kernel Version:             5.4.0-110-generic\n",
      "  OS Image:                   Ubuntu 20.04.4 LTS\n",
      "  Operating System:           linux\n",
      "  Architecture:               amd64\n",
      "  Container Runtime Version:  containerd://1.6.4\n",
      "  Kubelet Version:            v1.23.7\n",
      "  Kube-Proxy Version:         v1.23.7\n",
      "PodCIDR:                      10.233.66.0/24\n",
      "PodCIDRs:                     10.233.66.0/24\n",
      "Non-terminated Pods:          (5 in total)\n",
      "  Namespace                   Name                                       CPU Requests  CPU Limits  Memory Requests  Memory Limits  Age\n",
      "  ---------                   ----                                       ------------  ----------  ---------------  -------------  ---\n",
      "  kube-system                 calico-node-t5nsj                          150m (7%)     300m (15%)  64M (1%)         500M (13%)     16m\n",
      "  kube-system                 kube-proxy-5q4lc                           0 (0%)        0 (0%)      0 (0%)           0 (0%)         17m\n",
      "  kube-system                 nginx-proxy-node2                          25m (1%)      0 (0%)      32M (0%)         0 (0%)         17m\n",
      "  kube-system                 nodelocaldns-r9trt                         100m (5%)     0 (0%)      70Mi (2%)        170Mi (4%)     15m\n",
      "  local-path-storage          local-path-provisioner-6957789775-hxkbg    0 (0%)        0 (0%)      0 (0%)           0 (0%)         15m\n",
      "Allocated resources:\n",
      "  (Total limits may be over 100 percent, i.e., overcommitted.)\n",
      "  Resource           Requests        Limits\n",
      "  --------           --------        ------\n",
      "  cpu                275m (14%)      300m (15%)\n",
      "  memory             169400320 (4%)  678257920 (18%)\n",
      "  ephemeral-storage  0 (0%)          0 (0%)\n",
      "  hugepages-1Gi      0 (0%)          0 (0%)\n",
      "  hugepages-2Mi      0 (0%)          0 (0%)\n",
      "Events:\n",
      "  Type     Reason                   Age                From             Message\n",
      "  ----     ------                   ----               ----             -------\n",
      "  Normal   Starting                 17m                kube-proxy       \n",
      "  Normal   NodeAllocatableEnforced  17m                kubelet          Updated Node Allocatable limit across pods\n",
      "  Warning  InvalidDiskCapacity      17m                kubelet          invalid capacity 0 on image filesystem\n",
      "  Normal   NodeHasSufficientMemory  17m (x2 over 17m)  kubelet          Node node2 status is now: NodeHasSufficientMemory\n",
      "  Normal   NodeHasNoDiskPressure    17m (x2 over 17m)  kubelet          Node node2 status is now: NodeHasNoDiskPressure\n",
      "  Normal   NodeHasSufficientPID     17m (x2 over 17m)  kubelet          Node node2 status is now: NodeHasSufficientPID\n",
      "  Normal   Starting                 17m                kubelet          Starting kubelet.\n",
      "  Normal   RegisteredNode           17m                node-controller  Node node2 event: Registered Node node2 in Controller\n",
      "  Normal   NodeReady                16m                kubelet          Node node2 status is now: NodeReady\n",
      "  Normal   NodeAllocatableEnforced  16m                kubelet          Updated Node Allocatable limit across pods\n",
      "  Warning  InvalidDiskCapacity      16m                kubelet          invalid capacity 0 on image filesystem\n",
      "  Normal   Starting                 16m                kubelet          Starting kubelet.\n",
      "  Normal   NodeHasNoDiskPressure    16m                kubelet          Node node2 status is now: NodeHasNoDiskPressure\n",
      "  Normal   NodeHasSufficientPID     16m                kubelet          Node node2 status is now: NodeHasSufficientPID\n",
      "  Normal   NodeNotReady             16m                kubelet          Node node2 status is now: NodeNotReady\n",
      "  Normal   NodeHasSufficientMemory  16m                kubelet          Node node2 status is now: NodeHasSufficientMemory\n",
      "  Normal   NodeReady                16m                kubelet          Node node2 status is now: NodeReady\n",
      "  Normal   Starting                 14m                kubelet          Starting kubelet.\n",
      "  Warning  InvalidDiskCapacity      14m                kubelet          invalid capacity 0 on image filesystem\n",
      "  Normal   NodeAllocatableEnforced  14m                kubelet          Updated Node Allocatable limit across pods\n",
      "  Normal   NodeHasSufficientMemory  14m (x8 over 14m)  kubelet          Node node2 status is now: NodeHasSufficientMemory\n",
      "  Normal   NodeHasNoDiskPressure    14m (x7 over 14m)  kubelet          Node node2 status is now: NodeHasNoDiskPressure\n",
      "  Normal   NodeHasSufficientPID     14m (x7 over 14m)  kubelet          Node node2 status is now: NodeHasSufficientPID\n"
     ]
    }
   ],
   "source": [
    "! kubectl describe node node2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1ac628b2-43bc-437c-ae58-f05b91f96df6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I0621 08:29:03.285330   17667 loader.go:372] Config loaded from file:  /root/.kube/config\n",
      "I0621 08:29:03.383947   17667 round_trippers.go:553] GET https://xxx.xxx.118.255:6443/api/v1/namespaces/default/pods?limit=500 200 OK in 87 milliseconds\n",
      "I0621 08:29:03.406591   17667 round_trippers.go:553] GET https://xxx.xxx.118.255:6443/api/v1/namespaces/default/replicationcontrollers?limit=500 200 OK in 22 milliseconds\n",
      "I0621 08:29:03.429737   17667 round_trippers.go:553] GET https://xxx.xxx.118.255:6443/api/v1/namespaces/default/services?limit=500 200 OK in 22 milliseconds\n",
      "I0621 08:29:03.453266   17667 round_trippers.go:553] GET https://xxx.xxx.118.255:6443/apis/apps/v1/namespaces/default/daemonsets?limit=500 200 OK in 22 milliseconds\n",
      "I0621 08:29:03.477488   17667 round_trippers.go:553] GET https://xxx.xxx.118.255:6443/apis/apps/v1/namespaces/default/deployments?limit=500 200 OK in 23 milliseconds\n",
      "I0621 08:29:03.504126   17667 round_trippers.go:553] GET https://xxx.xxx.118.255:6443/apis/apps/v1/namespaces/default/replicasets?limit=500 200 OK in 26 milliseconds\n",
      "I0621 08:29:03.527974   17667 round_trippers.go:553] GET https://xxx.xxx.118.255:6443/apis/apps/v1/namespaces/default/statefulsets?limit=500 200 OK in 22 milliseconds\n",
      "I0621 08:29:03.554193   17667 round_trippers.go:553] GET https://xxx.xxx.118.255:6443/apis/autoscaling/v2/namespaces/default/horizontalpodautoscalers?limit=500 200 OK in 25 milliseconds\n",
      "I0621 08:29:03.575977   17667 round_trippers.go:553] GET https://xxx.xxx.118.255:6443/apis/batch/v1/namespaces/default/cronjobs?limit=500 200 OK in 21 milliseconds\n",
      "I0621 08:29:03.598633   17667 round_trippers.go:553] GET https://xxx.xxx.118.255:6443/apis/batch/v1/namespaces/default/jobs?limit=500 200 OK in 22 milliseconds\n",
      "NAME                 TYPE        CLUSTER-IP   EXTERNAL-IP   PORT(S)   AGE\n",
      "service/kubernetes   ClusterIP   10.233.0.1   <none>        443/TCP   18m\n"
     ]
    }
   ],
   "source": [
    "# What's running in the default namespace ?\n",
    "! kubectl get all -v=6"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8ee8427-21df-4d9c-9491-a887a00758fe",
   "metadata": {},
   "source": [
    "## systemd status"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f17cb2bc-5834-4524-acb7-8cbe08b08239",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Permanently added 'xxx.xxx.118.255' (ECDSA) to the list of known hosts.\n",
      "● kubepods.slice - libcontainer container kubepods.slice\n",
      "     Loaded: loaded (/run/systemd/transient/kubepods.slice; transient)\n",
      "  Transient: yes\n",
      "    Drop-In: /run/systemd/transient/kubepods.slice.d\n",
      "             └─50-CPUShares.conf, 50-MemoryLimit.conf, 50-TasksMax.conf\n",
      "     Active: active since Tue 2022-06-21 08:10:25 UTC; 18min ago\n",
      "      Tasks: 134 (limit: 4194304)\n",
      "     Memory: 680.4M (limit: 3.2G)\n",
      "        CPU: 4min 27.195s\n",
      "     CGroup: /kubepods.slice\n",
      "             ├─kubepods-besteffort.slice\n",
      "             │ └─kubepods-besteffort-pod935dfb0c_6a7b_4e86_b869_791ffdc012fa.slice\n",
      "             │   ├─cri-containerd-5cfe5ec7e799618675dbed1386150c46203789db0197c5a2de2c1ab7ca3b8033.scope\n",
      "             │   │ └─14111 /pause\n",
      "             │   └─cri-containerd-7fa84426bf9bbacb46509748554195e442b91a1b34fd95ef34d61196fbe72f71.scope\n",
      "             │     └─14150 /usr/local/bin/kube-proxy --config=/var/lib/kube-proxy/config.conf --hostname-override=node1\n",
      "             ├─kubepods-burstable.slice\n",
      "             │ ├─kubepods-burstable-pod2fbc3880_56f0_43a6_88bc_c00bb6b77c73.slice\n",
      "             │ │ ├─cri-containerd-3a01469aca6583af608f4243cb5329219bdb21c7c62ded9ed2d714b3f8034e2f.scope\n",
      "             │ │ │ └─18970 /pause\n",
      "             │ │ └─cri-containerd-e34102f103a305b52c8630062150392efb8f7c2fe697d8e80901ec6f3b94489a.scope\n",
      "             │ │   └─19104 /node-cache -localip 169.254.25.10 -conf /etc/coredns/Corefile -upstreamsvc coredns\n",
      "             │ ├─kubepods-burstable-pod3449ed93_204c_4341_b54f_2767c66f7a1a.slice\n",
      "             │ │ ├─cri-containerd-3262be86a4ba4c56152558b2a2d4c2fbcad4e8adf5404f18534f8894df0c9cb9.scope\n",
      "             │ │ │ └─19022 /cluster-proportional-autoscaler --namespace=kube-system --default-params={\"linear\":{\"preventSinglePointFailure\":true,\"coresPerReplica\":256,\"nodesPerReplica\":16,\"min\":2}} --logtostderr=true --v=2 --configmap=dns-autoscaler --target=Deployment/coredns\n",
      "             │ │ └─cri-containerd-8abdae15082bb0f0d2551b8e35bd3eab7dad5c0eb2c53da01f8b3f2732af2c15.scope\n",
      "             │ │   └─18909 /pause\n",
      "             │ ├─kubepods-burstable-pod503b5b2b_6579_4dac_a1e1_0dc9a8807b83.slice\n",
      "             │ │ ├─cri-containerd-b2167c17d5ec157c84ac862b933a60e1557853f1c2b6ec63f05e680b8f425b23.scope\n",
      "             │ │ │ └─15098 /pause\n",
      "             │ │ └─cri-containerd-eb70bbf421f7461ba2a7a8a2f7e326bba4179717772ee333ff49928ad9c493c1.scope\n",
      "             │ │   ├─15814 /usr/local/bin/runsvdir -P /etc/service/enabled\n",
      "             │ │   ├─15910 runsv felix\n",
      "             │ │   ├─15911 runsv node-status-reporter\n",
      "             │ │   ├─15912 runsv allocate-tunnel-addrs\n",
      "             │ │   ├─15913 runsv monitor-addresses\n",
      "             │ │   ├─15914 runsv cni\n",
      "             │ │   ├─15915 calico-node -status-reporter\n",
      "             │ │   ├─15916 calico-node -monitor-token\n",
      "             │ │   ├─15917 calico-node -monitor-addresses\n",
      "             │ │   ├─15918 calico-node -allocate-tunnel-addrs\n",
      "             │ │   └─15919 calico-node -felix\n",
      "             │ ├─kubepods-burstable-pod53ca5b56a5a7ea86a844b1ad3ead30fe.slice\n",
      "             │ │ ├─cri-containerd-930acebfef325d8436ab7e31a4b706d7a6a6785e1b9383a32b15bcbc8eadd329.scope\n",
      "             │ │ │ └─13615 kube-controller-manager --allocate-node-cidrs=true --authentication-kubeconfig=/etc/kubernetes/controller-manager.conf --authorization-kubeconfig=/etc/kubernetes/controller-manager.conf --bind-address=0.0.0.0 --client-ca-file=/etc/kubernetes/ssl/ca.crt --cluster-cidr=10.233.64.0/18 --cluster-name=cluster.local --cluster-signing-cert-file=/etc/kubernetes/ssl/ca.crt --cluster-signing-key-file=/etc/kubernetes/ssl/ca.key --configure-cloud-routes=false --controllers=*,bootstrapsigner,tokencleaner --kubeconfig=/etc/kubernetes/controller-manager.conf --leader-elect=true --leader-elect-lease-duration=15s --leader-elect-renew-deadline=10s --node-cidr-mask-size=24 --node-monitor-grace-period=40s --node-monitor-period=5s --profiling=False --requestheader-client-ca-file=/etc/kubernetes/ssl/front-proxy-ca.crt --root-ca-file=/etc/kubernetes/ssl/ca.crt --service-account-private-key-file=/etc/kubernetes/ssl/sa.key --service-cluster-ip-range=10.233.0.0/18 --terminated-pod-gc-threshold=12500 --use-service-account-credentials=true\n",
      "             │ │ └─cri-containerd-d5ea5b059d5d9b2d55951d9a947475e56e77a24e5ef22e68737db5b6303fa2d3.scope\n",
      "             │ │   └─13520 /pause\n",
      "             │ ├─kubepods-burstable-pod6a52576e8cbd37ebd89bef862cc3d511.slice\n",
      "             │ │ ├─cri-containerd-65fe09191c542088786e921d11ff29b39dc3bb99d62a4e6f7e3539c64509ea04.scope\n",
      "             │ │ │ └─21285 kube-apiserver --advertise-address=xxx.xxx.118.255 --allow-privileged=true --anonymous-auth=True --apiserver-count=1 --authorization-mode=Node,RBAC --bind-address=0.0.0.0 --client-ca-file=/etc/kubernetes/ssl/ca.crt --default-not-ready-toleration-seconds=300 --default-unreachable-toleration-seconds=300 --enable-admission-plugins=NodeRestriction --enable-aggregator-routing=False --enable-bootstrap-token-auth=true --endpoint-reconciler-type=lease --etcd-cafile=/etc/ssl/etcd/ssl/ca.pem --etcd-certfile=/etc/ssl/etcd/ssl/node-node1.pem --etcd-keyfile=/etc/ssl/etcd/ssl/node-node1-key.pem --etcd-servers=https://xxx.xxx.118.255:2379 --event-ttl=1h0m0s --insecure-port=0 --kubelet-client-certificate=/etc/kubernetes/ssl/apiserver-kubelet-client.crt --kubelet-client-key=/etc/kubernetes/ssl/apiserver-kubelet-client.key --kubelet-preferred-address-types=InternalDNS,InternalIP,Hostname,ExternalDNS,ExternalIP --profiling=False --proxy-client-cert-file=/etc/kubernetes/ssl/front-proxy-client.crt --proxy-client-key-file=/etc/kubernetes/ssl/front-proxy-client.key --request-timeout=1m0s --requestheader-allowed-names=front-proxy-client --requestheader-client-ca-file=/etc/kubernetes/ssl/front-proxy-ca.crt --requestheader-extra-headers-prefix=X-Remote-Extra- --requestheader-group-headers=X-Remote-Group --requestheader-username-headers=X-Remote-User --secure-port=6443 --service-account-issuer=https://kubernetes.default.svc.cluster.local --service-account-key-file=/etc/kubernetes/ssl/sa.pub --service-account-lookup=True --service-account-signing-key-file=/etc/kubernetes/ssl/sa.key --service-cluster-ip-range=10.233.0.0/18 --service-node-port-range=30000-32767 --storage-backend=etcd3 --tls-cert-file=/etc/kubernetes/ssl/apiserver.crt --tls-private-key-file=/etc/kubernetes/ssl/apiserver.key\n",
      "             │ │ └─cri-containerd-ded6a4c94ff1af05379a8702dc905129e1b79f2a215ec14c4078f6320448cda3.scope\n",
      "             │ │   └─21253 /pause\n",
      "             │ ├─kubepods-burstable-podb2e1cb3c9d385b5574667e3ff82a9929.slice\n",
      "             │ │ ├─cri-containerd-452f00ee37c3233f4f2f0b87ccf514dbddcffa9face01b70ae8328cb576e8b8a.scope\n",
      "             │ │ │ └─13604 kube-scheduler --authentication-kubeconfig=/etc/kubernetes/scheduler.conf --authorization-kubeconfig=/etc/kubernetes/scheduler.conf --bind-address=0.0.0.0 --config=/etc/kubernetes/kubescheduler-config.yaml --kubeconfig=/etc/kubernetes/scheduler.conf --leader-elect=true\n",
      "             │ │ └─cri-containerd-b26b06d965e4720d49a01fc88d1949ba83a2b26fdef549c90db200f057a2d036.scope\n",
      "             │ │   └─13547 /pause\n",
      "             │ └─kubepods-burstable-pode965c609_2719_4fb2_aef8_81670d806de8.slice\n",
      "             │   ├─cri-containerd-050ae7dbe7e99ee6350db461fed7755d0d91bdb31e18ed7b4e05c7b1cd360912.scope\n",
      "             │   │ └─18300 /pause\n",
      "             │   └─cri-containerd-08900a303d0047ccabd179145c898482b3843cda0d53d6bf74a77e35e6ed0900.scope\n",
      "             │     └─18482 /coredns -conf /etc/coredns/Corefile\n",
      "             └─kubepods-pod1e13aa72_eff3_4488_b3fd_18d87552b1c4.slice\n",
      "               ├─cri-containerd-d591daeba0c8181a7f81510ab9f47bdbc8cdac187c89796b4421418d299e2334.scope\n",
      "               │ └─20087 /metrics-server --logtostderr --cert-dir=/tmp --secure-port=4443 --kubelet-preferred-address-types=InternalIP,ExternalIP,Hostname --kubelet-use-node-status-port --kubelet-insecure-tls --metric-resolution=15s\n",
      "               └─cri-containerd-ddcf410af15c235df920ae988e5c76891016c8f10475d7f552a807a76ae630a2.scope\n",
      "                 └─19898 /pause\n",
      "\n",
      "Jun 21 08:10:25 node1 systemd[1]: Created slice libcontainer container kubepods.slice.\n"
     ]
    }
   ],
   "source": [
    "! ssh node1 systemctl status kubepods.slice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5d8561b9-2fb3-4153-872d-1f3b0d9aeb69",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Permanently added 'xxx.xxx.118.255' (ECDSA) to the list of known hosts.\n",
      "CONTAINER    IMAGE    RUNTIME    \n"
     ]
    }
   ],
   "source": [
    "# anything running through containerd ?\n",
    "! ssh node1 ctr c ls"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac04eded-914d-491a-a25a-01ae52058c36",
   "metadata": {},
   "source": [
    "## etcd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ab25ee8d-1d34-4c9c-b4c1-2c9176a74dfb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "e2315c91870fade, started, etcd1, https://xxx.xxx.118.255:2380, https://xxx.xxx.118.255:2379, false\n"
     ]
    }
   ],
   "source": [
    "# How many etcd instances are in my cluster ?\n",
    "\n",
    "! ssh -q node1 'etcdctl member list --cert=\"/etc/ssl/etcd/ssl/node-node1.pem\" --key=\"/etc/ssl/etcd/ssl/node-node1-key.pem\"'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6c44ed11-143c-44a5-a611-232c868f5e3b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/registry/apiextensions.k8s.io/customresourcedefinitions/bgpconfigurations.crd.projectcalico.org\n",
      "\n",
      "/registry/apiextensions.k8s.io/customresourcedefinitions/bgppeers.crd.projectcalico.org\n",
      "\n",
      "/registry/apiextensions.k8s.io/customresourcedefinitions/blockaffinities.crd.projectcalico.org\n",
      "\n",
      "/registry/apiextensions.k8s.io/customresourcedefinitions/caliconodestatuses.crd.projectcalico.org\n",
      "\n",
      "/registry/apiextensions.k8s.io/customresourcedefinitions/clusterinformations.crd.projectcalico.org\n",
      "\n",
      "/registry/apiextensions.k8s.io/customresourcedefinitions/felixconfigurations.crd.projectcalico.org\n",
      "\n",
      "/registry/apiextensions.k8s.io/customresourcedefinitions/globalnetworkpolicies.crd.projectcalico.org\n",
      "\n",
      "/registry/apiextensions.k8s.io/customresourcedefinitions/globalnetworksets.crd.projectcalico.org\n",
      "\n",
      "/registry/apiextensions.k8s.io/customresourcedefinitions/hostendpoints.crd.projectcalico.org\n",
      "\n",
      "/registry/apiextensions.k8s.io/customresourcedefinitions/ipamblocks.crd.projectcalico.org\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# List first 20 keys from etcd\n",
    "! ssh -q node1 'etcdctl get --from-key \"\" --keys-only --cert=\"/etc/ssl/etcd/ssl/node-node1.pem\" --key=\"/etc/ssl/etcd/ssl/node-node1-key.pem\" | head -20'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7e06028c-a88d-4847-b9f2-e3b81c574b6e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/registry/services/endpoints/default/kubernetes\n",
      "\n",
      "/registry/services/endpoints/kube-system/coredns\n",
      "\n",
      "/registry/services/endpoints/kube-system/metrics-server\n",
      "\n",
      "/registry/services/specs/default/kubernetes\n",
      "\n",
      "/registry/services/specs/kube-system/coredns\n",
      "\n",
      "/registry/services/specs/kube-system/metrics-server\n",
      "\n",
      "/registry/storageclasses/local-path\n",
      "\n",
      "compact_rev_key\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# get services\n",
    "! ssh -q node1 'etcdctl get --from-key \"/registry/services\" --keys-only --cert=\"/etc/ssl/etcd/ssl/node-node1.pem\" --key=\"/etc/ssl/etcd/ssl/node-node1-key.pem\" | head -20'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "41f2c22e-2b6f-42ee-9f2a-154810575af8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/registry/services/endpoints/default/kubernetes\n",
      "k8s\u0000\n",
      "\u000F\n",
      "\u0002v1\u0012\tEndpoints\u0012�\u0002\n",
      "�\u0002\n",
      "\n",
      "kubernetes\u0012\u0000\u001A\u0007default\"\u0000*$55a15631-e868-426c-b1f8-43691d028e5c2\u00008��ŕ\u0006\u0010\u0000Z/\n",
      "'endpointslice.kubernetes.io/skip-mirror\u0012\u0004truez\u0000�\u0001�\u0001\n",
      "\u000Ekube-apiserver\u0012\u0006Update\u001A\u0002v��ŕ\u0006\u0010\u0000FieldsV1:d\n",
      "b{\"f:metadata\":{\"f:labels\":{\".\":{},\"f:endpointslice.kubernetes.io/skip-mirror\":{}}},\"f:subsets\":{}}B\u0000\u0012&\n",
      "\u0013\n",
      "\u000Fxxx.xxx.118.255\u001A\u0000\u001A\u000F\n",
      "\u0005https\u0010�2\u001A\u0003TCP\u001A\u0000\"\u0000\n"
     ]
    }
   ],
   "source": [
    "# what's in our kubernetes services ?\n",
    "\n",
    "! ssh -q node1 'etcdctl get /registry/services/endpoints/default/kubernetes --cert=\"/etc/ssl/etcd/ssl/node-node1.pem\" --key=\"/etc/ssl/etcd/ssl/node-node1-key.pem\" | head -20'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ae45707-049f-49d0-be84-b53931eec1e8",
   "metadata": {},
   "source": [
    "## containerd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a49a08a8-1bf3-4e36-93d7-f9a5b5be9cc4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CONTAINER ID    IMAGE                                               COMMAND                   CREATED           STATUS    PORTS    NAMES\n",
      "44be767ddda7    k8s.gcr.io/pause:3.3                                \"/pause\"                  18 minutes ago    Up                 k8s://kube-system/kube-proxy-5q4lc                                                         \n",
      "4d413e3cdfd9    k8s.gcr.io/pause:3.3                                \"/pause\"                  16 minutes ago    Up                 k8s://local-path-storage/local-path-provisioner-6957789775-hxkbg                           \n",
      "5820e4af380f    docker.io/rancher/local-path-provisioner:v0.0.21    \"local-path-provisio…\"    16 minutes ago    Up                 k8s://local-path-storage/local-path-provisioner-6957789775-hxkbg/local-path-provisioner    \n",
      "5a03896ebe6b    k8s.gcr.io/kube-proxy:v1.23.7                       \"/usr/local/bin/kube…\"    18 minutes ago    Up                 k8s://kube-system/kube-proxy-5q4lc/kube-proxy                                              \n",
      "721bcf069918    k8s.gcr.io/dns/k8s-dns-node-cache:1.21.1            \"/node-cache -locali…\"    16 minutes ago    Up                 k8s://kube-system/nodelocaldns-r9trt/node-cache                                            \n",
      "765d1c54560c    k8s.gcr.io/pause:3.3                                \"/pause\"                  16 minutes ago    Up                 k8s://kube-system/nodelocaldns-r9trt                                                       \n",
      "9865349b2135    quay.io/calico/node:v3.22.3                         \"start_runit\"             17 minutes ago    Up                 k8s://kube-system/calico-node-t5nsj/calico-node                                            \n",
      "a563ffa10d6d    k8s.gcr.io/pause:3.3                                \"/pause\"                  18 minutes ago    Up                 k8s://kube-system/nginx-proxy-node2                                                        \n",
      "b4e67d80e0cd    k8s.gcr.io/pause:3.3                                \"/pause\"                  17 minutes ago    Up                 k8s://kube-system/calico-node-t5nsj                                                        \n",
      "e79d2fdc5f7b    docker.io/library/nginx:1.21.4                      \"/docker-entrypoint.…\"    18 minutes ago    Up                 k8s://kube-system/nginx-proxy-node2/nginx-proxy                                            \n",
      "\n",
      "Printing just the images: \n",
      "\n",
      "docker.io/library/nginx:1.21.4\n",
      "docker.io/rancher/local-path-provisioner:v0.0.21\n",
      "k8s.gcr.io/dns/k8s-dns-node-cache:1.21.1\n",
      "k8s.gcr.io/kube-proxy:v1.23.7\n",
      "k8s.gcr.io/pause:3.3\n",
      "quay.io/calico/node:v3.22.3\n"
     ]
    }
   ],
   "source": [
    "# Which containers are running on node2 ?\n",
    "! ssh -q node2 \"nerdctl ps\"\n",
    "! echo \"\\nPrinting just the images: \\n\"\n",
    "! ssh -q node2 \"nerdctl ps | tail -n +2 | tr -s ' ' | cut -d' ' -f2 | sort | uniq\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ace6cd71-3b8f-42a2-b199-ab32cbac6d46",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CONTAINER ID    IMAGE                                       COMMAND                   CREATED           STATUS    PORTS    NAMES\n",
      "26c178c96135    k8s.gcr.io/pause:3.3                        \"/pause\"                  17 minutes ago    Up                 k8s://kube-system/calico-kube-controllers-6dd874f784-x2bbk                            \n",
      "41f656a16a5f    docker.io/library/nginx:1.21.4              \"/docker-entrypoint.…\"    18 minutes ago    Up                 k8s://kube-system/nginx-proxy-node3/nginx-proxy                                       \n",
      "543ce2ddc8de    k8s.gcr.io/pause:3.3                        \"/pause\"                  18 minutes ago    Up                 k8s://kube-system/kube-proxy-n6b5d                                                    \n",
      "6b48de264141    k8s.gcr.io/coredns/coredns:v1.8.6           \"/coredns -conf /etc…\"    16 minutes ago    Up                 k8s://kube-system/coredns-76b4fb4578-rk7zt/coredns                                    \n",
      "79531790844a    k8s.gcr.io/pause:3.3                        \"/pause\"                  16 minutes ago    Up                 k8s://kube-system/coredns-76b4fb4578-rk7zt                                            \n",
      "92f53d19b723    k8s.gcr.io/dns/k8s-dns-node-cache:1.21.1    \"/node-cache -locali…\"    16 minutes ago    Up                 k8s://kube-system/nodelocaldns-bph5j/node-cache                                       \n",
      "9312f10d2531    quay.io/calico/kube-controllers:v3.22.3     \"/usr/bin/kube-contr…\"    17 minutes ago    Up                 k8s://kube-system/calico-kube-controllers-6dd874f784-x2bbk/calico-kube-controllers    \n",
      "b90d670cfaba    k8s.gcr.io/pause:3.3                        \"/pause\"                  17 minutes ago    Up                 k8s://kube-system/calico-node-spg5v                                                   \n",
      "c5cc7ee6ad2b    k8s.gcr.io/pause:3.3                        \"/pause\"                  18 minutes ago    Up                 k8s://kube-system/nginx-proxy-node3                                                   \n",
      "cc164544a0c6    quay.io/calico/node:v3.22.3                 \"start_runit\"             17 minutes ago    Up                 k8s://kube-system/calico-node-spg5v/calico-node                                       \n",
      "ccb63b4fc1b6    k8s.gcr.io/kube-proxy:v1.23.7               \"/usr/local/bin/kube…\"    18 minutes ago    Up                 k8s://kube-system/kube-proxy-n6b5d/kube-proxy                                         \n",
      "d1db9ed01430    k8s.gcr.io/pause:3.3                        \"/pause\"                  16 minutes ago    Up                 k8s://kube-system/nodelocaldns-bph5j                                                  \n",
      "\n",
      "Printing just the images: \n",
      "\n",
      "docker.io/library/nginx:1.21.4\n",
      "k8s.gcr.io/coredns/coredns:v1.8.6\n",
      "k8s.gcr.io/dns/k8s-dns-node-cache:1.21.1\n",
      "k8s.gcr.io/kube-proxy:v1.23.7\n",
      "k8s.gcr.io/pause:3.3\n",
      "quay.io/calico/kube-controllers:v3.22.3\n",
      "quay.io/calico/node:v3.22.3\n"
     ]
    }
   ],
   "source": [
    "# Which containers are running on node3 ?\n",
    "! ssh -q node3 \"nerdctl ps\"\n",
    "! echo \"\\nPrinting just the images: \\n\"\n",
    "! ssh -q node3 \"nerdctl ps | tail -n +2 | tr -s ' ' | cut -d' ' -f2 | sort | uniq\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13aef0dd-0f6e-49fd-ad42-8cdb8ea98c16",
   "metadata": {},
   "source": [
    "* quay.io/calico/kube-controllers is only running on node 2\n",
    "* k8s.gcr.io/coredns/coredns is only running on node 2\n",
    "* docker.io/rancher/local-path-provisioner is only running on node 3\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b014de91-9dc7-440f-b678-a1a4e318e03e",
   "metadata": {},
   "source": [
    "## metrics server\n",
    "\n",
    "**The metrics pipline needs to be installed in the cluster**\n",
    "\n",
    "See [https://kubernetes.io/docs/tasks/debug/debug-cluster/resource-metrics-pipeline/](https://kubernetes.io/docs/tasks/debug/debug-cluster/resource-metrics-pipeline/)\n",
    "\n",
    "To activate with kubespray make sure `metrics_server_enabled: true` is set in addons.yaml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5a6bc8fd-a4c5-4e66-9ad6-4b6759af1128",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NAME    CPU(cores)   CPU%   MEMORY(bytes)   MEMORY%   \n",
      "node1   444m         24%    1540Mi          47%       \n"
     ]
    }
   ],
   "source": [
    "! kubectl top node node1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "38c69648-1356-435b-9e53-58c199c34b33",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NAME                              CPU(cores)   MEMORY(bytes)   \n",
      "metrics-server-5c8c77d7b8-stkx7   8m           16Mi            \n"
     ]
    }
   ],
   "source": [
    "# What's the top of the metrics-server ?\n",
    "! kubectl top po $(kubectl get po -n kube-system | grep metrics | tr -s ' ' | cut -d' ' -f1) -n kube-system"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}